{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RealMe\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "import os\n",
    "val = os.getcwd()\n",
    "print(val)\n",
    "add = val + '/Documents/data.txt'\n",
    "\n",
    "data = open(val + '/Documents/data.txt',encoding=\"utf8\").read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hai': 1, 'ki': 2, 'ke': 3, 'se': 4, 'to': 5, 'hain': 6, 'me': 7, 'men': 8, 'bhi': 9, 'tum': 10, 'mein': 11, 'nhi': 12, 'ham': 13, 'ne': 14, 'main': 15, 'aur': 16, 'koi': 17, 'kaudi': 18, 'si': 19, 'nahin': 20, 'ko': 21, 'jab': 22, 'ho': 23, 'hu': 24, 'aap': 25, 'hi': 26, 'zindagi': 27, 'kar': 28, 'do': 29, 'ye': 30, 'mere': 31, 'raat': 32, 'hua': 33, 'mujhe': 34, 'or': 35, 'tu': 36, 'pr': 37, 'di': 38, 'kuchh': 39, 'jaise': 40, 'ek': 41, 'dil': 42, 'hotā': 43, 'chand': 44, 'nahi': 45, 'tere': 46, 'teri': 47, 'karta': 48, 'tha': 49, 'rehne': 50, 'paale': 51, 'woh': 52, 'jaengi': 53, 'har': 54, 'saath': 55, 'shaam': 56, 'aankh': 57, 'tanhā': 58, 'vaqt': 59, 'is': 60, 'kisi': 61, 'intizār': 62, 'ādatan': 63, 'kiyā': 64, 'jis': 65, 'ānkhon': 66, 'kati': 67, 'sadiyon': 68, 'karte': 69, 'ruk': 70, 'mile': 71, 'jaane': 72, 'din': 73, 'aise': 74, 'ruke': 75, 'baar': 76, 'chale': 77, 'qarār': 78, 'paas': 79, 'bhar': 80, 'thi': 81, 'apne': 82, 'inme': 83, 'aate': 84, 'kaala': 85, 'hoon': 86, 'dhoop': 87, 'lakeeren': 88, 'toh': 89, 'aao': 90, 'do…': 91, 'hath': 92, 'na': 93, 'tumhare': 94, 'jaaoon': 95, 'pakad': 96, 'lena': 97, 'dena': 98, 'hum': 99, 'mjhe': 100, 'gyi': 101, 'baat': 102, 'kyun': 103, 'pyaar': 104, 'kiya': 105, 'rang': 106, 'ka': 107, 'jo': 108, 'vo': 109, 'siva': 110, 'baad': 111, 'ghadi': 112, 'guzāri': 113, 'nami': 114, 'aaj': 115, 'phir': 116, 'kami': 117, 'yuun': 118, 'hui': 119, 'basar': 120, 'qāfila': 121, 'safar': 122, 'rahtā': 123, 'kahin': 124, 'tik': 125, 'aadat': 126, 'aadmi': 127, 'kabhi': 128, 'chaunk': 129, 'dekhe': 130, 'hamāri': 131, 'taraf': 132, 'dikhe': 133, 'diye': 134, 'vaade': 135, \"e'tibār\": 136, 'thiin': 137, 'sadiyān': 138, 'us': 139, 'judā': 140, 'i': 141, 'haath': 142, 'chhūten': 143, 'rishte': 144, 'chhoḍā': 145, 'shāḳh': 146, 'lamhe': 147, 'toḍā': 148, 'kitni': 149, 'lambi': 150, 'ḳhāmoshi': 151, 'guzrā': 152, 'huun': 153, 'un': 154, 'kitnā': 155, 'kahne': 156, 'koshish': 157, 'aksar': 158, 'tumhāri': 159, 'rāhon': 160, 'apnā': 161, 'tumhāre': 162, 'ḳhvāb': 163, 'shab': 164, 'lipat': 165, 'sote': 166, 'sazā': 167, 'en': 168, 'bhej': 169, 'ḳhatāen': 170, 'bheji': 171, 'ḳhushbū': 172, 'log': 173, 'afsāne': 174, 'purānā': 175, 'ḳhat': 176, 'kholā': 177, 'anjāne': 178, 'udaas': 179, 'kaun': 180, 'ās': 181, 'pās': 182, 'der': 183, 'gūnjte': 184, 'sannāte': 185, 'pukārtā': 186, 'guzārtā': 187, 'ehsān': 188, 'utārtā': 189, 'qadam': 190, 'de': 191, 'tire': 192, 'dar': 193, 'be': 194, 'shukr': 195, 'terā': 196, 'ġham': 197, 'rahā': 198, 'varna': 199, 'rulā': 200, 'diyā': 201, 'ummiden': 202, 'nichodi': 203, 'aahen': 204, 'tapkin': 205, 'pighlāen': 206, 'saktā': 207, 'sānsen': 208, 'niklen': 209, 'bhare': 210, 'reze': 211, 'ujālā': 212, 'ānkhen': 213, 'jhapakte': 214, 'rahte': 215, 'maazi': 216, 'justujū': 217, 'bahār': 218, 'piile': 219, 'patte': 220, 'talāsh': 221, 'karti': 222, 'uu': 223, 'gumshuda': 224, 'pada': 225, 'baitha': 226, 'sirhane': 227, 'takiyaa': 228, 'tale': 229, 'bus': 230, 'paal': 231, 'kaa': 232, 'intzaar': 233, 'kab': 234, 'palak': 235, 'aks': 236, 'dundhtaa': 237, 'kho': 238, 'jana': 239, 'chalataa': 240, 'baddi': 241, 'hasrath': 242, 'takta': 243, 'tujhe': 244, 'apna': 245, 'laksh': 246, 'panna': 247, 'chahta': 248, 'mathey': 249, 'pe': 250, 'bachpan': 251, 'chot': 252, 'daag': 253, 'nazar': 254, 'rodein': 255, 'patthar': 256, 'gulelon': 257, 'khela': 258, 'bohot': 259, 'kaha': 260, 'aawara': 261, 'ulkaon': 262, 'sangat': 263, 'thhik': 264, 'milogi': 265, 'pata': 266, 'chalega': 267, 'gaya': 268, 'haashiye': 269, 'likha': 270, 'jal': 271, 'itna': 272, 'jitna': 273, 'sulag': 274, 'siyaah': 275, 'rooth': 276, 'gusse': 277, 'shayad': 278, 'khinch': 279, 'thin': 280, 'inhee': 281, 'ab': 282, 'banao': 283, 'pala': 284, 'kabadi': 285, 'khelte': 286, 'lalkaro': 287, 'par': 288, 'maro': 289, 'bhago': 290, 'tumhe': 291, 'pakdoon': 292, 'liptoon': 293, 'tumhein': 294, 'wapas': 295, 'doon': 296, 'lakeerein': 297, 'chhune': 298, 'chhoone': 299, 'sarhad': 300, 'laqeerein': 301, 'cheez': 302, 'jise': 303, 'khte': 304, 'bhool': 305, 'gye': 306, 'rkhkr': 307, 'khi': 308, 'ajeeb': 309, 'rishta': 310, 'khwaishon': 311, 'darmiyaan': 312, 'jeene': 313, 'deti': 314, 'unhe': 315, 'mrne': 316, 'deta': 317, 'kyon': 318, 'lga': 319, 'khud': 320, 'mulakaat': 321, 'kuch': 322, 'kha': 323, 'magar': 324, 'noor': 325, 'duur': 326, 'ehsaas': 327, 'dooriyan': 328, 'maana': 329, 'milon': 330, 'faaslein': 331, 'sahi': 332, 'aitbaar': 333, 'bujh': 334, 'saari': 335, 'awaazein': 336, 'yaade': 337, 'reh': 338, 'tasveerein': 339, 'bachengi': 340, 'aankho': 341, 'baate': 342, 'sb': 343, 'beh': 344, 'aankhon': 345, 'sadiyaan': 346, 'usne': 347, 'judaai': 348, 'baahon': 349, 'kate': 350, 'subah': 351, 'badi': 352, 'halki': 353, 'lagti': 354, 'teeno': 355, 'banjare': 356, 'nam': 357, 'palkon': 358, 'krte': 359, 'mukhtsar': 360, 'tumhara': 361, 'intezaar': 362, 'kitne': 363, 'jaate': 364, 'rukhsaaro': 365, 'hayaa': 366, 'gulabi': 367, 'chdi': 368, 'kohsaaro': 369, 'socha': 370, 'jhoot': 371, 'mehsoos': 372, 'paap': 373, 'rooh': 374, 'aag': 375, 'jalte': 376, 'jism': 377, 'jhoota': 378, 'taap': 379, 'mushkil': 380, 'aakash': 381, 'chlna': 382, 'taare': 383, 'pairo': 384, 'chubhte': 385, 'tumse': 386, 'mili': 387, 'hmne': 388, 'abhi': 389, 'boi': 390}\n",
      "391\n"
     ]
    }
   ],
   "source": [
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 7s 379ms/step - loss: 6.7547 - accuracy: 0.0232\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 7s 364ms/step - loss: 5.8272 - accuracy: 0.0596\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 6s 332ms/step - loss: 5.2455 - accuracy: 0.0695\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 6s 329ms/step - loss: 4.4944 - accuracy: 0.1258\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 7s 350ms/step - loss: 3.5199 - accuracy: 0.2169\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 6s 331ms/step - loss: 2.3949 - accuracy: 0.4536\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 7s 358ms/step - loss: 1.4362 - accuracy: 0.6358\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 7s 344ms/step - loss: 0.8797 - accuracy: 0.7748\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 6s 333ms/step - loss: 0.5417 - accuracy: 0.8593\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 6s 323ms/step - loss: 0.3103 - accuracy: 0.9255\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.2512 - accuracy: 0.9338\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.1923 - accuracy: 0.9421\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.1857 - accuracy: 0.9338\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.1509 - accuracy: 0.9437\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.1418 - accuracy: 0.9371\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 6s 324ms/step - loss: 0.1223 - accuracy: 0.9404\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 6s 321ms/step - loss: 0.1387 - accuracy: 0.9421\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.1194 - accuracy: 0.9454\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.1235 - accuracy: 0.9404\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.1181 - accuracy: 0.9421\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.1169 - accuracy: 0.9437\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.1066 - accuracy: 0.9404\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.1071 - accuracy: 0.9454\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.1122 - accuracy: 0.9387\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.1138 - accuracy: 0.9437\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 6s 320ms/step - loss: 0.1124 - accuracy: 0.9387\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 6s 336ms/step - loss: 0.1018 - accuracy: 0.9454\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 6s 327ms/step - loss: 0.1091 - accuracy: 0.9387\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.1168 - accuracy: 0.9404\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.1026 - accuracy: 0.9454\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.1144 - accuracy: 0.9421\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 6s 336ms/step - loss: 0.1099 - accuracy: 0.9454\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.1019 - accuracy: 0.9404\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 6s 328ms/step - loss: 0.1113 - accuracy: 0.9387\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 6s 336ms/step - loss: 0.1111 - accuracy: 0.9404\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.1007 - accuracy: 0.9404\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.1021 - accuracy: 0.9354\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 6s 320ms/step - loss: 0.1075 - accuracy: 0.9437\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.0990 - accuracy: 0.9387\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.1128 - accuracy: 0.9371\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.0905 - accuracy: 0.9470\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.0946 - accuracy: 0.9470\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.0951 - accuracy: 0.9470\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 6s 315ms/step - loss: 0.0966 - accuracy: 0.9470\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 6s 320ms/step - loss: 0.0994 - accuracy: 0.9421\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 6s 339ms/step - loss: 0.0964 - accuracy: 0.9421\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 6s 328ms/step - loss: 0.0966 - accuracy: 0.9470\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 6s 315ms/step - loss: 0.0997 - accuracy: 0.9421\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 6s 316ms/step - loss: 0.0946 - accuracy: 0.9470\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.1102 - accuracy: 0.9338\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.0941 - accuracy: 0.9421\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 6s 313ms/step - loss: 0.0917 - accuracy: 0.9437\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.0953 - accuracy: 0.9404\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 6s 322ms/step - loss: 0.0933 - accuracy: 0.9487\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 6s 337ms/step - loss: 0.0886 - accuracy: 0.9470\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 7s 364ms/step - loss: 0.1017 - accuracy: 0.9503\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 7s 358ms/step - loss: 0.0923 - accuracy: 0.9437\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 7s 360ms/step - loss: 0.1000 - accuracy: 0.9404\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 7s 343ms/step - loss: 0.0922 - accuracy: 0.9421\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 6s 322ms/step - loss: 0.0929 - accuracy: 0.9454\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 6s 326ms/step - loss: 0.0896 - accuracy: 0.9387\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 6s 324ms/step - loss: 0.0912 - accuracy: 0.9421\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.0871 - accuracy: 0.9470\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 6s 314ms/step - loss: 0.0868 - accuracy: 0.9454\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 6s 312ms/step - loss: 0.0925 - accuracy: 0.9404\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 6s 322ms/step - loss: 0.0896 - accuracy: 0.9454\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 6s 326ms/step - loss: 0.0908 - accuracy: 0.9503\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 6s 329ms/step - loss: 0.0902 - accuracy: 0.9470\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 6s 331ms/step - loss: 0.0908 - accuracy: 0.9470\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.0876 - accuracy: 0.9503\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.0911 - accuracy: 0.9437\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 6s 340ms/step - loss: 0.0897 - accuracy: 0.9437\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 6s 321ms/step - loss: 0.0924 - accuracy: 0.9454\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 6s 322ms/step - loss: 0.0884 - accuracy: 0.9454\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 6s 323ms/step - loss: 0.0941 - accuracy: 0.9387\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 6s 314ms/step - loss: 0.0889 - accuracy: 0.9487\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.0853 - accuracy: 0.9487\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 6s 329ms/step - loss: 0.0905 - accuracy: 0.9437\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 6s 316ms/step - loss: 0.0863 - accuracy: 0.9437\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 6s 317ms/step - loss: 0.0869 - accuracy: 0.9454\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 6s 325ms/step - loss: 0.0943 - accuracy: 0.9421\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 6s 313ms/step - loss: 0.0855 - accuracy: 0.9470\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 6s 321ms/step - loss: 0.0900 - accuracy: 0.9470\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 6s 328ms/step - loss: 0.0846 - accuracy: 0.9421\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 6s 324ms/step - loss: 0.0903 - accuracy: 0.9421\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 6s 320ms/step - loss: 0.0901 - accuracy: 0.9387\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 6s 327ms/step - loss: 0.0844 - accuracy: 0.9520\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 6s 322ms/step - loss: 0.0864 - accuracy: 0.9454\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 6s 328ms/step - loss: 0.0899 - accuracy: 0.9387\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 6s 321ms/step - loss: 0.0863 - accuracy: 0.9437\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 6s 320ms/step - loss: 0.0914 - accuracy: 0.9437\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 6s 324ms/step - loss: 0.0906 - accuracy: 0.9404\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 6s 324ms/step - loss: 0.0851 - accuracy: 0.9487\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.0853 - accuracy: 0.9421\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 6s 320ms/step - loss: 0.0928 - accuracy: 0.9371\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 6s 321ms/step - loss: 0.0932 - accuracy: 0.9437\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 6s 322ms/step - loss: 0.0893 - accuracy: 0.9421\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 6s 323ms/step - loss: 0.0928 - accuracy: 0.9421\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 6s 319ms/step - loss: 0.0841 - accuracy: 0.9421\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 6s 320ms/step - loss: 0.0861 - accuracy: 0.9454\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002BA140A0550>\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 256, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(512)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(xs, ys, epochs=100, verbose=1)\n",
    "#print model.summary()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aao kabhi to chaunk ke dekhe koi hamāri taraf hai koi nhi men kar diye vaade hai\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"aao kabhi\"\n",
    "next_words = 15\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
